# SeeDot Architecture

This document describes the overall architecture of the SeeDot quantization tool. 

SeeDot is run by executing the `SeeDot-dev.py` python script. 

Running SeeDot using default arguments, i.e the call
```
    python SeeDot-dev.py
```
is equivalent to running the [ProtoNN](https://github.com/microsoft/EdgeML/blob/master/docs/publications/ProtoNN.pdf) algorithm with `fixed-point` encoding on the `cifar-binary` dataset for `x86` target device; i.e the call 
```
    python SeeDot-dev.py -a protonn -e fixed -d cifar-binary -n 1 -t x86 -m acc -l error
```

## Walkthrough

In this text, we will discuss the execution of SeeDot for the `FastGRNN` algorithm on the `usps10` dataset.
We'll discuss the execution for both Floating-point and Fixed-point encoding with `reduced disagreements` as the 
correctness metric. 

### Model and Datasets

For the run to take place, the model should be placed in the `model/fastgrnn/usps10/` directory, and the datasets 
should be placed in the `datasets/fastgrnn/usps10/` directory.
The steps in the walkthrough are based on the assumption that both these have been done. 
See [README.md](https://github.com/microsoft/EdgeML/blob/master/tools/SeeDot/README.md) for instructions on obtaining these. 

### Floating-point Encoding

The floating-point SeeDot for FastGRNN is run using the following command:
```
    python SeeDot-dev.py -a fastgrnn -e float -d usps10 -n 1 -t x86 -m red_disagree
```

On running this command, 

1. `main` function in `SeeDot-dev.py` initiates the `MainDriver` class in `SeeDot-dev.py`, which in turn initiates the `Main` class in `main.py`. 

2. In `seedot/main.py`, depending on the encoding, the `funForFloat` or `runForFixed` function is called. (In this case, `runForFloat` will be called). 

3. In `runForFloat`, first the `Converter` class in `seedot/compiler/converter/converter.py` is instantiated with the arguments `(encoding=float, datasetType=Testing, target=x86)`. 

    (The arguments here are for representation purposes and to explain the differences between the multiple Converter instances). 

4. In the `Converter` class, the SeeDot input files (all the model weights and, the train and test datasets) are processed to a format that is required by the SeeDot compiler. 

5. In `seedot/compiler/converter/coverter.py`, the quantization code is called that produces files used by the SeeDot compiler. 
    Depending on the encoding, `QuantizerFloat` or `QuantizerFixed` classes are instantiated for `float` and `fixed` encoding respectively. 
    These classes are defined in `seedot/compiler/converter/quantizer.py`. (In our case `QuantizerFloat`).

6. The `QuantizerFloat` class uses the `ParamsBuilder` class from `seedot/compiler/converter/paramsBuilder.py` to quantize the parameters. 

7. After the `Converter` class finished execution, the control return to `seedot/main.py:runForFloat`. 

8. Now, the `Compiler` class in `seedot/compiler/compiler.py` is instantiated. 

9. The `Compiler` class reads `model/fastgrnn/usps10/input.sd` and creates an **Abastract Syntax Tree (AST)**. 
    This step uses the tokens in `seedot/compiler/antlr/seedotTokens.py` and the grammar in `seedot/compiler/antlr/seedotParser.py` which are in turn generated by `ANTLR 4.7` software from `seedot/compiler/antlr/seedot.tokens` and `seedot/compiler/antlr/seedot.g4` respectively.

10. Then, type inference is performed on the AST followed by conversion to SeeDot's **Intermediate Representation (IR)**.
    This is done using the `IRBuilder` class in `seedot/compiler/ir/irBuilder.py`. This IR is a series of function calls (and the corresponding arguments) whose end result is the required output. This set of function calls is also referred to as the main body of SeeDot's inference. 

11. Once the IR is generated, the control is passed back to the `Compiler` class. 
    `Compiler` calls the target code-generator (for x86, `x86` class in `seedot/compiler/codegen/x86.py`; for Arduino, `Arduino` class in `seedot/compiler/codegen/arduino.py`; for M3, `M3` class in `seedot/compiler/codegen/m3.py`), which generates the CPP code for the target device specified.

12. After the code-generation, the Control is passed back to the `Compiler` which in turn passes the control back to `main.py:runForFloat`. 

13. `main.py:runForFloat` instatiates the `Predictor` class in `seedot/predictor.py`. 

14. `Predictor` builds the x86 temp files generated by the compiler. This build is supported for `Windows` and `Linux`. 

15. Once the build is completed, the code is run and the result is printed to the console. 

### Fixed-point Encoding

The fixed-point SeeDot for FastGRNN is run using the following command:
```
    python SeeDot-dev.py -a fastgrnn -e fixed -d usps10 -n 1 -t x86 -m red_disagree
```

On running this command, 

1. `main` function in `SeeDot-dev.py` initiates the `MainDriver` class in `SeeDot-dev.py`, which in turn initiates the `Main` class in `main.py`. 
2. In `seedot/main.py`, depending on the encoding, the `funForFloat` or `runForFixed` function is called. (In this case, `runForFixed` will be called). 
3. In `runForFixed`, first the `collectProfileData` function is called. This collects the data that helps determines the most efficient scale and bitwidth of variables.

4. In `collectProfileData` the `Converter` class in `seedot/compiler/converter/converter.py` is instantiated with the arguments `(encoding=float, datasetType=Training, target=x86)`. (The arguments here are for representation purposes and to explain the differences between the multiple Converter instances). 
5. In `Converter`, the quantization code is called that produces files used by the SeeDot compiler. Depending on the encoding, `QuantizerFloat` or `QuantizerFixed` classes are instantiated for `float` and `fixed` encoding respectively. These classes are defined in `seedot/compiler/converter/quantizer.py`. (In our case `QuantizerFoat`).
6. The `QuantizerFloat` class uses the `ParamsBuilder` class from `seedot/compiler/converter/paramsBuilder.py` to quantize the parameters. 
7. After the `Converter` class finished execution, the control return to `seedot/main.py:collectProfileData`.
8. Now, the `Compiler` class in `seedot/compiler/compiler.py` is instantiated. 
9. The `Compiler` class reads `model/fastgrnn/usps10/input.sd` and creates an **Abastract Syntax Tree (AST)**. 
    This step uses the tokens in `seedot/compiler/antlr/seedotTokens.py` and the grammar in `seedot/compiler/antlr/seedotParser.py` which are in turn generated by `ANTLR 4.7` software from `seedot/compiler/antlr/seedot.tokens` and `seedot/compiler/antlr/seedot.g4` respectively.
10. Then, type inference is performed on the AST followed by conversion to SeeDot's **Intermediate Representation (IR)**. 
    This is done using the `IRBuilder` class in `seedot/compiler/ir/irBuilder.py`. 
    This IR is a series of function calls (and the corresponding arguments) whose end result is the required output. This set of function calls is also referred to as the main body of SeeDot's inference. 
11. Once the IR is generated, the control is passed back to the `Compiler` class. 
    `Compiler` calls the target code-generator (for x86, `x86` class in `seedot/compiler/codegen/x86.py`; for Arduino, `Arduino` class in `seedot/compiler/codegen/arduino.py`; for M3, `M3` class in `seedot/compiler/codegen/m3.py`), which generates the CPP code for the target device specified. (In this case, `x86`).
12. After the code-generation, the Control is passed back to the `Compiler` which in turn passes the control back to `main.py:collectProfileData`. 
13. The x86 target code is built and run by the `Predictor` class in `seedot/predictor.py` called by `main.py:collectProfileData`.
14. This run of the x86 target code generates profiling data that is used by the next stages of SeeDot. 
15. The `Predictor` returns control to `main.py:collectProfileData` which in turn return control to `main.py:runForFixed`.

16. `main.py:runForFixed` starts the exploration by first instantiating and running a `Converter` in `seedot/compiler/converter/converter.py` with the arguments `(encoding=fixed, datasetType=Training, target=x86)`. 
    This in turn uses the `QuantizerFixed` in  `seedot/compiler/converter/quantizer.py`.
17. After the `Converter` returns, the control is passed to `main.py: performSearch`. 
18. `main.py: performSearch` performs the 4 stages of exploration to find the optimal bitwidth and scale allocation for each variable.
    1. Stage I: Determine the best scale for the input variable 'X'. 'X' is the variable that represents the input given to the inference model.
    2. Stage II: Determine the best scale for non-'X' variables. 
    3. Stage III: Demote variables one at a time to measure impact on the correctness of inference. 
    4. Stage IV: Demote variables cumulatively to find the most optimal assignment to reduce the model size and latency.

    Each of these stages calls the `Compiler` and `Predictor` multiple times to run the inference model. 
19. Once, the exploration is complete, `main.py: performSearch` stores the scale and bitwidth assignments as class variables and return control to `main.py:runForFixed`. 
20. `main.py:runForFixed` calls the `Predictor` class to obtain the final inference accuracy. 
21. Finally, if the target is non-x86, then `main.py:runForFixed` calls the `Compiler` class which generates the code for the target device using the code-generators mentioned in point 11 above.
22. The target codes are stored in `arduinodump/` for Arduino and `m3dump/` for M3 by default. 
